# Agent System

Core agent system implementing **Retrieval-Augmented Generation (RAG)** with **intelligent tool routing** and **self-reflection** for financial Q&A. This powers the chat and analysis features on stratalens.ai.

## Architecture Overview

The agent follows a **broad-to-deep** execution pattern:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HIGH-LEVEL FLOW                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚   Question â”€â”€â–º Analyze & Route â”€â”€â–º Retrieve from Tools â”€â”€â–º Generate     â”‚
â”‚                     â”‚                      â”‚                    â”‚        â”‚
â”‚                     â”‚                      â”‚                    â–¼        â”‚
â”‚                     â”‚                      â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                     â”‚                      â”‚              â”‚ Evaluate â”‚   â”‚
â”‚                     â”‚                      â”‚              â”‚ Quality  â”‚   â”‚
â”‚                     â”‚                      â”‚              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                      â”‚                   â”‚         â”‚
â”‚                     â”‚                      â”‚         confident?â”‚         â”‚
â”‚                     â”‚                      â”‚              NO â”€â”€â”´â”€â”€ YES   â”‚
â”‚                     â”‚                      â”‚              â”‚         â”‚    â”‚
â”‚                     â”‚                      â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â–¼    â”‚
â”‚                     â”‚                   (iterate)            Final Answerâ”‚
â”‚                     â”‚                                                    â”‚
â”‚                     â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚   â”‚              TOOL ROUTING (Question Analyzer)            â”‚           â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚           â”‚
â”‚   â”‚  â”‚  Earnings   â”‚ â”‚  SEC 10-K   â”‚ â”‚   Real-Time     â”‚    â”‚           â”‚
â”‚   â”‚  â”‚ Transcripts â”‚ â”‚   Filings   â”‚ â”‚     News        â”‚    â”‚           â”‚
â”‚   â”‚  â”‚  (default)  â”‚ â”‚             â”‚ â”‚    (Tavily)     â”‚    â”‚           â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Concepts:**
1. **Question Analysis** - LLM determines which data sources to query
2. **Tool Routing** - Routes to earnings transcripts, SEC filings, or news
3. **Self-Reflection** - Evaluates answer quality and iterates if needed (Agent Mode)

---

## Self-Reflection Loop (Agent Mode)

When running in Agent Mode (`max_iterations > 1`), the system performs iterative self-improvement. This is the core intelligence that separates a simple RAG from an agentic system.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ITERATION LOOP                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚ Generate Answer  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚       â”‚
â”‚           â”‚                                              â”‚       â”‚
â”‚           â–¼                                              â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚       â”‚
â”‚  â”‚ Evaluate Quality â”‚                                   â”‚       â”‚
â”‚  â”‚ â€¢ completeness   â”‚                                   â”‚       â”‚
â”‚  â”‚ â€¢ accuracy       â”‚                                   â”‚       â”‚
â”‚  â”‚ â€¢ clarity        â”‚                                   â”‚       â”‚
â”‚  â”‚ â€¢ specificity    â”‚                                   â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚       â”‚
â”‚           â”‚                                              â”‚       â”‚
â”‚           â–¼                                              â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      YES    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚       â”‚
â”‚  â”‚ Should Iterate?  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚ Generate        â”‚   â”‚       â”‚
â”‚  â”‚ (confidence<0.9) â”‚             â”‚ Follow-up       â”‚ â”€â”€â”˜       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚ Questions       â”‚           â”‚
â”‚           â”‚ NO                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚           â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
â”‚  â”‚   Final Answer   â”‚                                           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Evaluation Criteria:**
- `completeness_score` (0-10): Does the answer fully address the question?
- `accuracy_score` (0-10): Is the information factually correct based on context?
- `clarity_score` (0-10): Is the answer well-structured and easy to understand?
- `specificity_score` (0-10): Does it include specific numbers, dates, quotes?
- `overall_confidence` (0-1): Weighted combination used for iteration decisions

**During iteration, the agent can autonomously decide to:**
- Search for more transcripts via `needs_transcript_search`
- Search for news via `needs_news_search` (triggers Tavily)

**Stopping Conditions:**
1. Confidence score â‰¥ 90% threshold
2. Agent determines answer is sufficient (`should_iterate=false`)
3. Max iterations reached
4. No follow-up questions generated

---

## Operating Modes

| Mode | Config | Latency | Use Case |
|------|--------|---------|----------|
| **Chat Mode** | `max_iterations=1` | ~3-5s | Production on stratalens.ai |
| **Agent Mode** | `max_iterations=3-4` | ~10-20s | Local testing, complex queries |

---

## How the Agent Chooses Tools

The agent doesn't blindly search all sources. It uses **LLM-based routing** in the Question Analyzer to determine which data sources to use based on the question's content.

### Data Source Routing (Question Analyzer)

When a question comes in, `question_analyzer.py` uses Cerebras LLM to analyze it and returns a `data_source` field:

| `data_source` Value | Description | Tools Used |
|---------------------|-------------|------------|
| `earnings_transcripts` | Default - quarterly earnings questions | Earnings transcript vector search |
| `10k` | Annual report questions (financials, compensation, risks) | SEC 10-K filing search |
| `latest_news` | Current events, breaking news | Tavily real-time news API |
| `hybrid` | Questions needing multiple sources | Combination of above |

**Routing Rules (from question_analyzer.py):**

```
10K is chosen when question contains:
â”œâ”€â”€ "10k", "10-k", "annual report", "SEC filing"
â”œâ”€â”€ "balance sheet", "income statement", "cash flow statement"
â”œâ”€â”€ "executive compensation", "CEO salary", "CEO pay"
â”œâ”€â”€ "risk factors", "legal proceedings", "MD&A"
â””â”€â”€ "assets", "liabilities", "stockholders equity"

LATEST_NEWS is chosen when question contains:
â”œâ”€â”€ "latest news", "recent news", "current news", "breaking news"
â”œâ”€â”€ "what's happening", "latest updates", "recent developments"
â””â”€â”€ Questions about very recent events (within days/weeks)

EARNINGS_TRANSCRIPTS is the default for:
â”œâ”€â”€ Quarterly performance questions
â”œâ”€â”€ Management commentary and guidance
â”œâ”€â”€ Analyst Q&A discussions
â””â”€â”€ Revenue, margins, growth discussions
```

### Tool Execution Flow (rag_agent.py)

After routing, `rag_agent.py` orchestrates tool execution in this order:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    QUESTION ANALYSIS                              â”‚
â”‚  question_analyzer.py determines:                                 â”‚
â”‚  â€¢ data_source: "10k" | "latest_news" | "earnings_transcripts"   â”‚
â”‚  â€¢ needs_10k: boolean                                             â”‚
â”‚  â€¢ needs_latest_news: boolean                                     â”‚
â”‚  â€¢ extracted_tickers: ["AAPL", "MSFT"]                           â”‚
â”‚  â€¢ quarter_context: "latest" | "multiple" | "specific"           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STAGE 2.5: NEWS SEARCH                         â”‚
â”‚  IF needs_latest_news == true:                                    â”‚
â”‚    â†’ tavily_service.search_news(query)                           â”‚
â”‚    â†’ Returns: articles with titles, URLs, content, dates         â”‚
â”‚    â†’ Formats as context with [N1], [N2] citation markers         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STAGE 2.6: 10-K SEARCH                         â”‚
â”‚  IF data_source in ["10k", "hybrid"] OR needs_10k == true:       â”‚
â”‚    â†’ sec_filings_service.search_10k_filings_advanced_async()     â”‚
â”‚    â†’ Uses LLM section routing (Cerebras)                         â”‚
â”‚    â†’ Uses LLM table selection (Cerebras)                         â”‚
â”‚    â†’ Hybrid search + cross-encoder reranking                     â”‚
â”‚    â†’ Returns chunks with [10K1], [10K2] markers                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STAGE 3: TRANSCRIPT SEARCH                     â”‚
â”‚  IF data_source NOT in ["10k", "latest_news"]:                   â”‚
â”‚    â†’ search_engine.search_similar_chunks()                       â”‚
â”‚    â†’ Vector search (70%) + keyword BM25 (30%)                    â”‚
â”‚    â†’ Returns chunks with citation markers                        â”‚
â”‚    â†’ SKIPPED if pure 10K or news-only query                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STAGE 4: RESPONSE GENERATION                   â”‚
â”‚  All context combined â†’ response_generator                       â”‚
â”‚  â€¢ news_context (from Tavily)                                    â”‚
â”‚  â€¢ ten_k_context (from SEC service)                              â”‚
â”‚  â€¢ transcript chunks (from search engine)                        â”‚
â”‚  â†’ Single LLM call with all available context                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Deep Dive: Tavily (Real-Time News)

`tavily_service.py` provides real-time web search for current events that aren't in historical transcripts or filings.

### When Tavily is Used

1. **Question Analyzer Detection**: If question contains news keywords, sets `needs_latest_news=true`
2. **Agent Mode Iteration**: During self-reflection, if the agent determines current information is needed, it can trigger Tavily search via `needs_news_search` in evaluation

### How Tavily Works

```python
# tavily_service.py
class TavilyService:
    def search_news(self, query: str, max_results: int = 5, include_answer: str = "advanced"):
        """
        Searches Tavily API for latest news articles.

        Returns:
            {
                "answer": "AI-generated summary of results",
                "results": [
                    {
                        "title": "Article headline",
                        "url": "https://...",
                        "content": "Article text preview",
                        "published_date": "2024-01-15",
                        "score": 0.95
                    }
                ]
            }
        """

    def format_news_context(self, news_results):
        """Formats results with [N1], [N2] citation markers for LLM context"""

    def get_news_citations(self, news_results):
        """Extracts citation metadata for frontend display"""
```

### Example Flow

```
User: "What's the latest news on NVIDIA?"

1. Question Analyzer:
   - Detects "latest news" keyword
   - Sets data_source="latest_news", needs_latest_news=true
   - Extracts ticker: NVDA

2. rag_agent.py Stage 2.5:
   - Calls tavily_service.search_news("What's the latest news on NVIDIA? NVDA")
   - Returns 5 recent articles

3. Context Formation:
   === LATEST NEWS (from Tavily) ===
   Summary: NVIDIA announced record Q4 earnings...

   [N1] NVIDIA Stock Surges on AI Chip Demand
      Published: 2024-01-20
      Source: https://reuters.com/...
      NVIDIA's stock rose 5% following...

   [N2] Jensen Huang Keynote at CES 2024
      ...
   === END NEWS ===

4. Response Generator:
   - Receives news_context parameter
   - Generates answer citing [N1], [N2]
```

## Deep Dive: SEC 10-K Filings

`sec_filings_service.py` provides sophisticated access to annual SEC 10-K filings with LLM-based intelligent routing.

### When 10-K is Used

1. **Explicit Request**: Question mentions "10k", "10-K", "annual report", "SEC filing"
2. **Content Detection**: Questions about balance sheets, income statements, executive compensation, risk factors
3. **Automatic Detection**: Executive compensation questions ALWAYS use 10-K (this data isn't in earnings transcripts)

### 10-K Search Pipeline (4 Stages)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 0: LLM Section Routing (Cerebras)                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  Question: "What are Apple's risk factors?"                      â”‚
â”‚                                                                   â”‚
â”‚  LLM analyzes and routes to relevant SEC sections:               â”‚
â”‚  â†’ ["item_1a"] (Risk Factors section)                            â”‚
â”‚                                                                   â”‚
â”‚  Quantitative questions â†’ item_7 (MD&A), item_8 (Financials)     â”‚
â”‚  Qualitative questions â†’ item_1 (Business), item_1a (Risks)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: Hybrid Search (TF-IDF + Semantic)                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Semantic search: 70% weight (vector similarity)               â”‚
â”‚  â€¢ Keyword search: 30% weight (TF-IDF)                           â”‚
â”‚  â€¢ Filter by routed sections from Phase 0                        â”‚
â”‚  â€¢ Retrieve ~100 candidate chunks                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: Cross-Encoder Reranking                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                            â”‚
â”‚  â€¢ Uses cross-encoder/ms-marco-MiniLM-L-6-v2                     â”‚
â”‚  â€¢ Scores each (query, chunk) pair for relevance                 â”‚
â”‚  â€¢ Reorders results by cross-encoder score                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: LLM-Based Table Selection (Cerebras)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  â€¢ Fetches ALL tables for the ticker from ten_k_tables           â”‚
â”‚  â€¢ Prioritizes core financial statements:                        â”‚
â”‚    ğŸŒŸ Income Statement (revenue, profit, expenses)               â”‚
â”‚    ğŸŒŸ Balance Sheet (assets, liabilities, equity)                â”‚
â”‚    ğŸŒŸ Cash Flow Statement (cash flows, capex)                    â”‚
â”‚  â€¢ LLM selects 2-5 most relevant tables                          â”‚
â”‚  â€¢ Selected tables placed BEFORE text chunks in context          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Table Selection Prompt (Cerebras LLM)

The agent uses a detailed prompt for intelligent table selection:

```python
# From sec_filings_service.py
prompt = """
QUESTION: {question}

AVAILABLE TABLES:
1. [ğŸŒŸ CORE FINANCIAL STATEMENT] Income Statement (item_8) - income_statement
2. [ğŸŒŸ CORE FINANCIAL STATEMENT] Balance Sheet (item_8) - balance_sheet
3. Revenue by Segment (item_7)
...

STEP 1: DEEP QUESTION ANALYSIS
- What EXACTLY is being asked?
- Identify key financial metrics
- Determine if numbers, ratios, or trends needed

STEP 2: SYSTEMATIC TABLE EVALUATION
- For EACH table: Does it DIRECTLY answer the question?
- Create relevance score (1-10)

STEP 3: MAKE SELECTION
- PRIORITIZE core financial statements marked with ğŸŒŸ
- Maximum 5 tables, prefer fewer highly relevant ones
- Quality over quantity

Return JSON:
{"selected_table_indices": [1, 2, 5], "reasoning": "..."}
"""
```

### Example 10-K Flow

```
User: "What was Tim Cook's compensation in 2023?"

1. Question Analyzer:
   - Detects "compensation" keyword
   - Sets data_source="10k", needs_10k=true
   - Note: Executive compensation is ONLY in 10-K filings

2. sec_filings_service Phase 0 (Section Routing):
   - LLM routes to: ["item_11"] (Executive Compensation)

3. Stage 1 (Hybrid Search):
   - Searches item_11 chunks for "compensation" "Tim Cook"
   - Returns 100 candidate chunks

4. Stage 2 (Cross-Encoder Reranking):
   - Reranks by relevance to exact question
   - Top chunks about CEO compensation float up

5. Stage 3 (Table Selection):
   - LLM sees: "Executive Compensation Table", "Stock Awards", etc.
   - Selects: Summary Compensation Table, Stock Awards Table

6. Context Formation:
   === 10-K SEC FILINGS DATA ===
   [10K1] AAPL - FY2023 - Executive Compensation
   Type: Financial Table
   Content: [Summary Compensation Table with Tim Cook's salary...]

   [10K2] AAPL - FY2023 - Executive Compensation
   Content: The CEO's total compensation for fiscal 2023...
   === END 10-K ===

7. Response Generation:
   - Uses ten_k_context parameter
   - Generates answer with specific salary figures
```

## Earnings Transcript Search

For quarterly earnings questions, the agent uses hybrid search over transcript chunks.

### Search Strategy

```python
# search_engine.py
def search_similar_chunks(query, top_k, quarter):
    """
    Hybrid search combining:
    - Vector search: 70% weight (semantic similarity via pgvector)
    - Keyword search: 30% weight (BM25 via PostgreSQL full-text)
    """
```

### Chunk Storage

```
PostgreSQL Table: transcript_chunks
â”œâ”€â”€ chunk_text: TEXT (1000 chars max, 200 overlap)
â”œâ”€â”€ embedding: VECTOR (all-MiniLM-L6-v2, 384 dimensions)
â”œâ”€â”€ ticker: VARCHAR (e.g., "AAPL")
â”œâ”€â”€ year: INTEGER (e.g., 2024)
â”œâ”€â”€ quarter: INTEGER (1-4)
â””â”€â”€ metadata: JSONB
```

## Key Components

### Core Files

| File | Description |
|------|-------------|
| `agent.py` | Main entry point - unified Agent API for financial Q&A |
| `rag/rag_agent.py` | Orchestration engine with tool routing and self-reflection |
| `rag/question_analyzer.py` | LLM-based query analysis and data source routing (Cerebras) |

### Data Sources (Tools)

| File | Tool | Description |
|------|------|-------------|
| `rag/search_engine.py` | Transcript Search | Hybrid vector + keyword search over earnings transcripts |
| `rag/sec_filings_service.py` | 10-K Search | SEC annual filings with LLM section routing and table selection |
| `rag/tavily_service.py` | News Search | Real-time news via Tavily API |

### Supporting Components

| File | Description |
|------|-------------|
| `rag/response_generator.py` | LLM response generation with streaming and quality evaluation |
| `rag/database_manager.py` | PostgreSQL/pgvector operations and connection pooling |
| `rag/conversation_memory.py` | Multi-turn conversation state for context-aware questions |
| `prompts.py` | Centralized LLM prompt templates |
| `rag/config.py` | RAG configuration (chunk sizes, search weights, model names) |

## Data Storage

### Database Schema

```
PostgreSQL + pgvector
â”œâ”€â”€ transcript_chunks       # Earnings call transcripts
â”‚   â”œâ”€â”€ chunk_text          # 1000 chars, 200 overlap
â”‚   â”œâ”€â”€ embedding           # all-MiniLM-L6-v2 (384 dim)
â”‚   â”œâ”€â”€ ticker, year, quarter
â”‚   â””â”€â”€ metadata (JSONB)
â”‚
â”œâ”€â”€ ten_k_chunks            # 10-K filing text
â”‚   â”œâ”€â”€ chunk_text, embedding
â”‚   â”œâ”€â”€ sec_section         # item_1, item_7, item_8, etc.
â”‚   â”œâ”€â”€ sec_section_title   # Human-readable section name
â”‚   â””â”€â”€ is_financial_statement
â”‚
â””â”€â”€ ten_k_tables            # 10-K extracted tables (JSONB)
    â”œâ”€â”€ content             # Table data
    â”œâ”€â”€ statement_type      # income_statement, balance_sheet, cash_flow
    â””â”€â”€ is_financial_statement
```

## Key Features

**Intelligent Tool Routing:**
- LLM-based data source selection (earnings, 10-K, news)
- Automatic detection of question intent
- Skip unnecessary searches based on question type

**Multi-Source RAG:**
- Earnings transcripts: Hybrid vector + keyword search
- SEC 10-K filings: LLM section routing + table selection + cross-encoder reranking
- Real-time news: Tavily API integration

**Core Capabilities:**
- Multi-ticker comparative analysis (up to 8 tickers)
- Quarter-aware filtering (e.g., "Q4 2024", "latest quarter", "last 3 quarters")
- Citation tracking with source attribution ([N1] for news, [10K1] for filings)
- Streaming response generation
- Multi-turn conversation memory

## Limitations

- Requires `$TICKER` format for company identification
- Quarter availability varies by company
- Companies describe fiscal years differently (cross-company comparison challenges)
- No real-time stock price data
- No strict evals for earnings transcripts at the moment

## Usage

```python
from agent import create_agent

agent = create_agent()

# Earnings transcript question (automatic routing)
result = await agent.execute_rag_flow_async(
    question="What did $AAPL say about iPhone sales in Q4 2024?",
    max_iterations=1
)

# 10-K question (automatically routes to SEC filings)
result = await agent.execute_rag_flow_async(
    question="What was Tim Cook's compensation in 2023?",
    max_iterations=1
)

# News question (automatically routes to Tavily)
result = await agent.execute_rag_flow_async(
    question="What's the latest news on $NVDA?",
    max_iterations=1
)

# Streaming
async for event in agent.execute_rag_flow(
    question="Compare $MSFT and $GOOGL cloud revenue",
    max_iterations=1,
    stream=True
):
    if event['type'] == 'streaming_token':
        print(event['data'], end='', flush=True)
```

## Configuration

**Environment Variables**:
```bash
OPENAI_API_KEY=...           # Response generation
CEREBRAS_API_KEY=...         # Question analysis, section routing, table selection
TAVILY_API_KEY=...           # Real-time news search
DATABASE_URL=postgresql://...
```

**Agent Config** (`agent_config.py`):
- `max_iterations`: Refinement iterations (default: 4)
- `min_confidence_threshold`: Quality threshold for early stopping (default: 0.90)

**RAG Config** (`rag/config.py`):
- `chunks_per_quarter`: Max chunks per quarter (default: 15)
- `keyword_weight` / `vector_weight`: Hybrid search (0.3 / 0.7)
- `cerebras_model`: Question analysis model (default: qwen-3-235b)
- `openai_model`: Generation model (default: gpt-4.1-mini)

## Development Status

| Component | Status |
|-----------|--------|
| Earnings Transcript Search | âœ… Production |
| SEC 10-K Filing Search | âœ… Production |
| Tavily News Search | âœ… Production |
| LLM Data Source Routing | âœ… Production |
| Streaming | âœ… Production |
| Multi-ticker/quarter | âœ… Production |
| Conversation memory | âœ… Production |
| Agent mode (self-reflection) | ğŸ§ª Experimental |
| Screener agent | ğŸ§ª Experimental |

## Data Ingestion

See `agent/rag/data_ingestion/README.md` for transcript and 10-K ingestion pipelines.

## Related

- API endpoints: See main `README.md` in project root
- Prompt templates: `prompts.py`
- FastAPI integration: `fastapi_server.py`
